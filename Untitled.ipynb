{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import coo_matrix, hstack, vstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statistics as st\n",
    "\n",
    "from preprocessing_tools import prepare_processing\n",
    "import preprocessing_tools\n",
    "from stop_words_tools import find_stop_words_array, find_cat\n",
    "from confustion_matrix_tools import visualize_confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_tools.ENABLE_MORPHING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "category = pd.read_csv(\"category.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_limit = 5000\n",
    "train = train.head(n = hard_limit)\n",
    "X = train[\"description\"] + \" \" + train[\"title\"]\n",
    "X = X.iloc[:hard_limit].values\n",
    "X = prepare_processing(X)\n",
    "y = train.iloc[:hard_limit,-1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,\n",
    "                                                    random_state=42, shuffle = True)\n",
    "y_train_4cat = np.apply_along_axis(find_cat, 1, y_train.reshape((y_train.shape[0],1)))\n",
    "y_test_4cat = np.apply_along_axis(find_cat, 1, y_test.reshape((y_test.shape[0],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 232 ms, sys: 5.28 ms, total: 237 ms\n",
      "Wall time: 239 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "common_stop_words = [\"а\", \"е\", \"и\", \"ж\", \"м\", \"о\", \"на\", \"не\", \"ни\", \"об\", \"но\", \"он\", \"мне\", \"мои\", \"мож\", \"она\", \"они\", \"оно\", \"мной\", \"много\", \"многочисленное\", \"многочисленная\", \"многочисленные\", \"многочисленный\", \"мною\", \"мой\", \"мог\", \"могут\", \"можно\", \"может\", \"можхо\", \"мор\", \"моя\", \"моё\", \"мочь\", \"над\", \"нее\", \"оба\", \"нам\", \"нем\", \"нами\", \"ними\", \"мимо\", \"немного\", \"одной\", \"одного\", \"менее\", \"однажды\", \"однако\", \"меня\", \"нему\", \"меньше\", \"ней\", \"наверху\", \"него\", \"ниже\", \"мало\", \"надо\", \"один\", \"одиннадцать\", \"одиннадцатый\", \"назад\", \"наиболее\", \"недавно\", \"миллионов\", \"недалеко\", \"между\", \"низко\", \"меля\", \"нельзя\", \"нибудь\", \"непрерывно\", \"наконец\", \"никогда\", \"никуда\", \"нас\", \"наш\", \"нет\", \"нею\", \"неё\", \"них\", \"мира\", \"наша\", \"наше\", \"наши\", \"ничего\", \"начала\", \"нередко\", \"несколько\", \"обычно\", \"опять\", \"около\", \"мы\", \"ну\", \"нх\", \"от\", \"отовсюду\", \"особенно\", \"нужно\", \"очень\", \"отсюда\", \"в\", \"во\", \"вон\", \"вниз\", \"внизу\", \"вокруг\", \"вот\", \"восемнадцать\", \"восемнадцатый\", \"восемь\", \"восьмой\", \"вверх\", \"вам\", \"вами\", \"важное\", \"важная\", \"важные\", \"важный\", \"вдали\", \"везде\", \"ведь\", \"вас\", \"ваш\", \"ваша\", \"ваше\", \"ваши\", \"впрочем\", \"весь\", \"вдруг\", \"вы\", \"все\", \"второй\", \"всем\", \"всеми\", \"времени\", \"время\", \"всему\", \"всего\", \"всегда\", \"всех\", \"всею\", \"всю\", \"вся\", \"всё\", \"всюду\", \"г\", \"год\", \"говорил\", \"говорит\", \"года\", \"году\", \"где\", \"да\", \"ее\", \"за\", \"из\", \"ли\", \"же\", \"им\", \"до\", \"по\", \"ими\", \"под\", \"иногда\", \"довольно\", \"именно\", \"долго\", \"позже\", \"более\", \"должно\", \"пожалуйста\", \"значит\", \"иметь\", \"больше\", \"пока\", \"ему\", \"имя\", \"пор\", \"пора\", \"потом\", \"потому\", \"после\", \"почему\", \"почти\", \"посреди\", \"ей\", \"два\", \"две\", \"двенадцать\", \"двенадцатый\", \"двадцать\", \"двадцатый\", \"двух\", \"его\", \"дел\", \"или\", \"без\", \"день\", \"занят\", \"занята\", \"занято\", \"заняты\", \"действительно\", \"давно\", \"девятнадцать\", \"девятнадцатый\", \"девять\", \"девятый\", \"даже\", \"алло\", \"жизнь\", \"далеко\", \"близко\", \"здесь\", \"дальше\", \"для\", \"лет\", \"зато\", \"даром\", \"первый\", \"перед\", \"затем\", \"зачем\", \"лишь\", \"десять\", \"десятый\", \"ею\", \"её\", \"их\", \"бы\", \"еще\", \"при\", \"был\", \"про\", \"процентов\", \"против\", \"просто\", \"бывает\", \"бывь\", \"если\", \"люди\", \"была\", \"были\", \"было\", \"будем\", \"будет\", \"будете\", \"будешь\", \"прекрасно\", \"буду\", \"будь\", \"будто\", \"будут\", \"ещё\", \"пятнадцать\", \"пятнадцатый\", \"друго\", \"другое\", \"другой\", \"другие\", \"другая\", \"других\", \"есть\", \"пять\", \"быть\", \"лучше\", \"пятый\", \"к\", \"ком\", \"конечно\", \"кому\", \"кого\", \"когда\", \"которой\", \"которого\", \"которая\", \"которые\", \"который\", \"которых\", \"кем\", \"каждое\", \"каждая\", \"каждые\", \"каждый\", \"кажется\", \"как\", \"какой\", \"какая\", \"кто\", \"кроме\", \"куда\", \"кругом\", \"с\", \"т\", \"у\", \"я\", \"та\", \"те\", \"уж\", \"со\", \"то\", \"том\", \"снова\", \"тому\", \"совсем\", \"того\", \"тогда\", \"тоже\", \"собой\", \"тобой\", \"собою\", \"тобою\", \"сначала\", \"только\", \"уметь\", \"тот\", \"тою\", \"хорошо\", \"хотеть\", \"хочешь\", \"хоть\", \"хотя\", \"свое\", \"свои\", \"твой\", \"своей\", \"своего\", \"своих\", \"свою\", \"твоя\", \"твоё\", \"раз\", \"уже\", \"сам\", \"там\", \"тем\", \"чем\", \"сама\", \"сами\", \"теми\", \"само\", \"рано\", \"самом\", \"самому\", \"самой\", \"самого\", \"семнадцать\", \"семнадцатый\", \"самим\", \"самими\", \"самих\", \"саму\", \"семь\", \"чему\", \"раньше\", \"сейчас\", \"чего\", \"сегодня\", \"себе\", \"тебе\", \"сеаой\", \"человек\", \"разве\", \"теперь\", \"себя\", \"тебя\", \"седьмой\", \"спасибо\", \"слишком\", \"так\", \"такое\", \"такой\", \"такие\", \"также\", \"такая\", \"сих\", \"тех\", \"чаще\", \"четвертый\", \"через\", \"часто\", \"шестой\", \"шестнадцать\", \"шестнадцатый\", \"шесть\", \"четыре\", \"четырнадцать\", \"четырнадцатый\", \"сколько\", \"сказал\", \"сказала\", \"сказать\", \"ту\", \"ты\", \"три\", \"эта\", \"эти\", \"что\", \"это\", \"чтоб\", \"этом\", \"этому\", \"этой\", \"этого\", \"чтобы\", \"этот\", \"стал\", \"туда\", \"этим\", \"этими\", \"рядом\", \"тринадцать\", \"тринадцатый\", \"этих\", \"третий\", \"тут\", \"эту\", \"суть\", \"чуть\", \"тысяч\"]\n",
    "stop_words = find_stop_words_array(X_train, y_train_4cat) + common_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885333333333\n",
      "CPU times: user 705 ms, sys: 16.3 ms, total: 721 ms\n",
      "Wall time: 743 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_4_category = make_pipeline(CountVectorizer(min_df=1, ngram_range=(1, 1), stop_words=stop_words),\n",
    "                             TfidfTransformer(sublinear_tf=False, smooth_idf=True),\n",
    "                             LogisticRegression(solver='saga', multi_class='multinomial',\n",
    "                                                random_state=0)\n",
    "                            )\n",
    "pipeline_4_category.fit(X_train, y_train_4cat)\n",
    "print(accuracy_score(pipeline_4_category.predict(X_test), y_test_4cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class predict_model:\n",
    "    train = \"\"\n",
    "    X = \"\"\n",
    "    y = \"\"\n",
    "    X_train = \"\"\n",
    "    X_test = \"\"\n",
    "    y_train = \"\"\n",
    "    y_test = \"\"\n",
    "    pipeline = \"\"\n",
    "    y_predicted = \"\"\n",
    "    c_id_shift = 0\n",
    "    \n",
    "    def __init__(this, train, shift):\n",
    "        this.train = train\n",
    "        this.c_id_shift = shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = X\n",
    "train_light = train.drop(['title', 'description'], axis = 1)\n",
    "train_1 = train_light.query(\"category_id < 15\")\n",
    "train_2 = train_light.query(\"category_id < 30\").query(\"category_id >= 15\")\n",
    "train_3 = train_light.query(\"category_id < 42\").query(\"category_id >= 30\")\n",
    "train_4 = train_light.query(\"category_id >= 42\")\n",
    "models = [predict_model(train_1, 0), predict_model(train_2, 15), predict_model(train_3, 30), \n",
    "          predict_model(train_4, 42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.X = model.train.drop([\"item_id\", \"category_id\"], axis = 1)\n",
    "    model.y = model.train[\"category_id\"].values\n",
    "    model.X_train, model.X_test, model.y_train, model.y_test =\\\n",
    "    train_test_split(model.X, model.y, test_size=0.02, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814814814815\n",
      "0.862068965517\n",
      "0.869565217391\n",
      "0.695652173913\n"
     ]
    }
   ],
   "source": [
    "for mdl in models:\n",
    "    pipeline = make_pipeline(CountVectorizer(min_df=1, ngram_range=(1, 1), stop_words=stop_words),\n",
    "                         TfidfTransformer(sublinear_tf=False, smooth_idf=True),\n",
    "                         LogisticRegression(solver='saga', multi_class='multinomial',\n",
    "                                            random_state=0)\n",
    "                        )\n",
    "    pipeline.fit(mdl.X_train[\"text\"], mdl.y_train)\n",
    "    mdl.pipeline = pipeline\n",
    "    mdl.y_predicted = pipeline.predict(mdl.X_test[\"text\"])\n",
    "    print(accuracy_score(mdl.y_predicted, mdl.y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_by_4_cat = pipeline_4_category.predict(X_test)\n",
    "predict_by_all_cat = list()\n",
    "for i in range(predict_by_4_cat.shape[0]):\n",
    "    current_predict = models[predict_by_4_cat[i]].pipeline.predict([X_test[i]])\n",
    "    predict_by_all_cat.append(current_predict[0])\n",
    "predict_by_all_cat = np.array(predict_by_all_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86599999999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predict_by_all_cat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bd1cf73af407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmdl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvisualize_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Coding/ML/test-aufgabe-winter-2017/confustion_matrix_tools.py\u001b[0m in \u001b[0;36mvisualize_confusion_matrix\u001b[0;34m(confusion_matrix)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtmp_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mnorm_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAD8CAYAAADAKumpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCNwThSoIAvdEoQqCwD3/H/0Ydb/I8tDvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11061cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mdl in models:\n",
    "    visualize_confusion_matrix(confusion_matrix(mdl.y_test, mdl.y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_treshold_for_categories_to_recalculate(conf_matr):\n",
    "    data = []\n",
    "    for i in range(len(conf_matr)):\n",
    "        for j in range(len(conf_matr[0])):\n",
    "            if i != j:\n",
    "                data.append(conf_matr[i][j])\n",
    "    return st.mean(data) + 2 * st.stdev(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_pairs = []\n",
    "for mdl in models:\n",
    "    conf_matr = confusion_matrix(mdl.y_test, mdl.y_predicted)\n",
    "\n",
    "    category_pairs_to_recalculate_limit = 10\n",
    "    limit = calculate_treshold_for_categories_to_recalculate(conf_matr)\n",
    "    for i in range(len(conf_matr)):\n",
    "        for j in range(len(conf_matr[i])):\n",
    "            if i != j and conf_matr[i][j] > limit:\n",
    "                failed_pairs.append([i + mdl.c_id_shift, j + mdl.c_id_shift, conf_matr[i,j]])\n",
    "    failed_pairs.sort(key = lambda x: -x[2])\n",
    "    failed_pairs = failed_pairs[:category_pairs_to_recalculate_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_cat_refinementer(cid1, cid2):\n",
    "    _train_cat_1 = train_light.query(\"category_id == \" + str(cid1))\n",
    "    _train_cat_2 = train_light.query(\"category_id == \" + str(cid2))\n",
    "    _train_data = _train_cat_1.append(_train_cat_2)\n",
    "\n",
    "    _X = _train_data[\"text\"].values\n",
    "    _y = _train_data[\"category_id\"].values\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(_X, _y, test_size=0.05,\n",
    "                                                        random_state=42, shuffle = True)\n",
    "\n",
    "    _pipeline = make_pipeline(CountVectorizer(min_df=1, ngram_range=(1, 1), stop_words=stop_words),\n",
    "                             TfidfTransformer(sublinear_tf=False, smooth_idf=True),\n",
    "                             LogisticRegression(solver='saga', multi_class='multinomial', random_state=0))\n",
    "    _pipeline.fit(_X_train, _y_train)\n",
    "    return _pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in failed_pairs:\n",
    "    cid1 = pair[0]\n",
    "    cid2 = pair[1]\n",
    "    pipeline = pair_cat_refinementer(cid1, cid2)\n",
    "    predict_by_all_cat[predict_by_all_cat == cid1] = pipeline.predict(X_test[predict_by_all_cat == cid1])\n",
    "    predict_by_all_cat[predict_by_all_cat == cid2] = pipeline.predict(X_test[predict_by_all_cat == cid2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predict_by_all_cat, y_test)\n",
    "# 0.90181538377730563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # price column \n",
    "# def price_column(X):\n",
    "#     return np.array(\n",
    "#         scaler.fit_transform(X[\"price\"].values.reshape(len(X[\"price\"]), 1)))\n",
    "\n",
    "# count_vectorizer = CountVectorizer(min_df=1, ngram_range=(1, 2), stop_words=stop_words)\n",
    "# transformer = TfidfTransformer(sublinear_tf=False, smooth_idf=True)\n",
    "# regressor = LogisticRegression(max_iter = 100000, solver='saga', multi_class='multinomial', random_state=0)\n",
    "# scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "# ENABLE_PRICE_COLUMN = False\n",
    "# X1train_transformed = count_vectorizer.fit_transform(X1_train[\"text\"])\n",
    "# X1train_transformed = transformer.fit_transform(X1train_transformed)\n",
    "# if ENABLE_PRICE_COLUMN: X1train_transformed = hstack((X1train_transformed, price_column(X1_train)))\n",
    "# regressor.fit(X1train_transformed, y1_train)\n",
    "\n",
    "# X1test_transformed = count_vectorizer.transform(X1_test[\"text\"])\n",
    "# X1test_transformed = transformer.transform(X1test_transformed)\n",
    "# if ENABLE_PRICE_COLUMN: X1test_transformed = hstack((X1test_transformed, price_column(X1_test)))\n",
    "    \n",
    "# print(accuracy_score(regressor.predict(X1test_transformed), y1_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
